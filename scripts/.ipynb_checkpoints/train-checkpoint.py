# scripts/train.py
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import torch
import pandas as pd
import matplotlib.pyplot as plt
from models import UNet, BCEDiceLoss
from data.dataset import get_data_loaders
from training.trainer import UNetTrainer, get_optimizer, get_scheduler

def plot_training_history(history, save_path='training_history.png'):
    """ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss')
    if 'val_loss' in history and history['val_loss'][0] is not None:
        axes[0, 0].plot(history['epoch'], history['val_loss'], label='Val Loss')
    axes[0, 0].set_title('Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # å‡†ç¡®ç‡å’ŒmIoU
    axes[0, 1].plot(history['epoch'], history['train_accuracy'], label='Train Accuracy')
    axes[0, 1].plot(history['epoch'], history['train_miou'], label='Train mIoU')
    if 'val_accuracy' in history and history['val_accuracy'][0] is not None:
        axes[0, 1].plot(history['epoch'], history['val_accuracy'], '--', label='Val Accuracy')
        axes[0, 1].plot(history['epoch'], history['val_miou'], '--', label='Val mIoU')
    axes[0, 1].set_title('Accuracy & mIoU')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Score')
    axes[0, 1].legend()
    axes[0, 1].grid(True)
    
    # Diceå’ŒF1åˆ†æ•°
    axes[1, 0].plot(history['epoch'], history['train_dice'], label='Train Dice')
    axes[1, 0].plot(history['epoch'], history['train_f1'], label='Train F1')
    if 'val_dice' in history and history['val_dice'][0] is not None:
        axes[1, 0].plot(history['epoch'], history['val_dice'], '--', label='Val Dice')
        axes[1, 0].plot(history['epoch'], history['val_f1'], '--', label='Val F1')
    axes[1, 0].set_title('Dice & F1 Score')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Score')
    axes[1, 0].legend()
    axes[1, 0].grid(True)
    
    # ç²¾ç¡®ç‡å’Œå¬å›ç‡
    axes[1, 1].plot(history['epoch'], history['train_precision'], label='Train Precision')
    axes[1, 1].plot(history['epoch'], history['train_recall'], label='Train Recall')
    if 'val_precision' in history and history['val_precision'][0] is not None:
        axes[1, 1].plot(history['epoch'], history['val_precision'], '--', label='Val Precision')
        axes[1, 1].plot(history['epoch'], history['val_recall'], '--', label='Val Recall')
    axes[1, 1].set_title('Precision & Recall')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Score')
    axes[1, 1].legend()
    axes[1, 1].grid(True)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")

def save_metrics_to_csv(history, save_path='training_metrics.csv'):
    """ä¿å­˜æŒ‡æ ‡åˆ°CSVæ–‡ä»¶"""
    df = pd.DataFrame(history)
    df.to_csv(save_path, index=False)
    print(f"è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜è‡³: {save_path}")
    
    # æ‰“å°æœ€ç»ˆæŒ‡æ ‡
    print("\nğŸ¯ æœ€ç»ˆè®­ç»ƒç»“æœ:")
    final_metrics = {}
    for key in history:
        if key != 'epoch' and history[key]:
            final_metrics[key] = history[key][-1]
    
    # æ ¼å¼åŒ–è¾“å‡ºæœ€ç»ˆæŒ‡æ ‡
    metric_groups = [
        ['train_loss', 'val_loss'],
        ['train_accuracy', 'val_accuracy'],
        ['train_miou', 'val_miou'],
        ['train_dice', 'val_dice'],
        ['train_f1', 'val_f1'],
        ['train_precision', 'val_precision'],
        ['train_recall', 'val_recall']
    ]
    
    for group in metric_groups:
        for metric in group:
            if metric in final_metrics and final_metrics[metric] is not None:
                print(f"{metric:.<20} {final_metrics[metric]:.4f}")

def create_dummy_data_loader(batch_size=4, image_size=512, num_samples=32):
    """åˆ›å»ºè™šæ‹Ÿæ•°æ®åŠ è½½å™¨ç”¨äºæµ‹è¯•"""
    from torch.utils.data import Dataset, DataLoader
    import torch
    
    class DummyDataset(Dataset):
        def __len__(self):
            return num_samples
        
        def __getitem__(self, idx):
            # åˆ›å»ºéšæœºå›¾åƒå’Œæ©ç 
            image = torch.randn(3, image_size, image_size)
            # åˆ›å»ºåå‘èƒŒæ™¯çš„æ©ç ï¼ˆæ¨¡æ‹ŸçœŸå®æ•°æ®åˆ†å¸ƒï¼‰
            mask = torch.bernoulli(torch.full((1, image_size, image_size), 0.1)).float()
            return image, mask
    
    return DataLoader(DummyDataset(), batch_size=batch_size, shuffle=True)

def main():
    # é…ç½®å‚æ•°
    config = {
        'image_size': 512,
        'batch_size': 8,
        'epochs': 5,
        'learning_rate': 1e-4,
        'optimizer': 'adam',
        'loss_function': 'bce_dice',
        'scheduler': 'plateau',
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        
        # æ•°æ®è·¯å¾„ - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
        'train_image_dir': r'/root/autodl-tmp/dataset/all_need_dataset/images/train',
        'train_mask_dir': r'/root/autodl-tmp/dataset/all_need_dataset/mask/train',
        'val_image_dir': r'/root/autodl-tmp/dataset/all_need_dataset/images/val',
        'val_mask_dir': r'/root/autodl-tmp/dataset/all_need_dataset/mask/val',
        
        # ä½¿ç”¨è™šæ‹Ÿæ•°æ®ï¼ˆå¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼‰
        'use_dummy_data': False
    }
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ»‘å¡åˆ†å‰²UNetæ¨¡å‹")
    print("=" * 50)
    print(f"è®¾å¤‡: {config['device']}")
    print(f"å›¾åƒå°ºå¯¸: {config['image_size']}x{config['image_size']}")
    print(f"æ‰¹å¤§å°: {config['batch_size']}")
    print(f"è®­ç»ƒè½®æ•°: {config['epochs']}")
    print(f"å­¦ä¹ ç‡: {config['learning_rate']}")
    print("=" * 50)
    
    # åˆ›å»ºæ¨¡å‹
    model = UNet(n_channels=3, n_classes=1)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")
    
    # è·å–æ•°æ®åŠ è½½å™¨
    if config.get('use_dummy_data', False):
        print("ä½¿ç”¨è™šæ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
        train_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
        val_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")
    else:
        try:
            train_loader, val_loader = get_data_loaders(
                train_image_dir=config['train_image_dir'],
                train_mask_dir=config['train_mask_dir'],
                val_image_dir=config['val_image_dir'],
                val_mask_dir=config['val_mask_dir'],
                batch_size=config['batch_size'],
                image_size=config['image_size']
            )
            print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
            if val_loader:
                print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("åˆ‡æ¢åˆ°è™šæ‹Ÿæ•°æ®æ¨¡å¼...")
            train_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
            val_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
    
    # è®¾ç½®æŸå¤±å‡½æ•° - ä¿®æ­£è¿™é‡Œï¼
    if config['loss_function'] == 'bce':
        criterion = nn.BCEWithLogitsLoss()
    elif config['loss_function'] == 'dice':
        from models.losses import DiceLoss
        criterion = DiceLoss()
    else:  # bce_dice
        criterion = BCEDiceLoss(bce_weight=0.5, dice_weight=0.5)  # ä¿®æ­£å‚æ•°å
    
    # è®¾ç½®ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨
    optimizer = get_optimizer(model, config['optimizer'], config['learning_rate'])
    scheduler = get_scheduler(optimizer, config['scheduler'])
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = UNetTrainer(model, config['device'], train_loader, val_loader)
    
    print("\nå¼€å§‹è®­ç»ƒ...")
    history = trainer.train(
        epochs=config['epochs'],
        optimizer=optimizer,
        criterion=criterion,
        scheduler=scheduler,
        save_path='run/bcd_dice_5epoch/best_landslide_unet.pth'
    )
    
    # ä¿å­˜ç»“æœ
    plot_training_history(history)
    save_metrics_to_csv(history)
    
    print("\nâœ… è®­ç»ƒå®Œæˆ!")
    return model, history

if __name__ == "__main__":
    model, history = main()