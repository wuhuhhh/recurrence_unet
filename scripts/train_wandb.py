# scripts/train.py
import sys
import os
import torch
import pandas as pd
import matplotlib.pyplot as plt
import wandb  # å¯¼å…¥wandb

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from models import UNet, BCEDiceLoss,ResidualUNet
from data.dataset import get_data_loaders
from training.trainer import UNetTrainer, get_optimizer, get_scheduler


def plot_training_history(history, save_path='training_history.png'):
    # ä¿æŒåŸæœ‰å®ç°ä¸å˜
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss')
    if 'val_loss' in history and history['val_loss'][0] is not None:
        axes[0, 0].plot(history['epoch'], history['val_loss'], label='Val Loss')
    axes[0, 0].set_title('Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # å‡†ç¡®ç‡å’ŒmIoU
    axes[0, 1].plot(history['epoch'], history['train_accuracy'], label='Train Accuracy')
    axes[0, 1].plot(history['epoch'], history['train_miou'], label='Train mIoU')
    if 'val_accuracy' in history and history['val_accuracy'][0] is not None:
        axes[0, 1].plot(history['epoch'], history['val_accuracy'], '--', label='Val Accuracy')
        axes[0, 1].plot(history['epoch'], history['val_miou'], '--', label='Val mIoU')
    axes[0, 1].set_title('Accuracy & mIoU')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Score')
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # Diceå’ŒF1åˆ†æ•°
    axes[1, 0].plot(history['epoch'], history['train_dice'], label='Train Dice')
    axes[1, 0].plot(history['epoch'], history['train_f1'], label='Train F1')
    if 'val_dice' in history and history['val_dice'][0] is not None:
        axes[1, 0].plot(history['epoch'], history['val_dice'], '--', label='Val Dice')
        axes[1, 0].plot(history['epoch'], history['val_f1'], '--', label='Val F1')
    axes[1, 0].set_title('Dice & F1 Score')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Score')
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # ç²¾ç¡®ç‡å’Œå¬å›ç‡
    axes[1, 1].plot(history['epoch'], history['train_precision'], label='Train Precision')
    axes[1, 1].plot(history['epoch'], history['train_recall'], label='Train Recall')
    if 'val_precision' in history and history['val_precision'][0] is not None:
        axes[1, 1].plot(history['epoch'], history['val_precision'], '--', label='Val Precision')
        axes[1, 1].plot(history['epoch'], history['val_recall'], '--', label='Val Recall')
    axes[1, 1].set_title('Precision & Recall')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Score')
    axes[1, 1].legend()
    axes[1, 1].grid(True)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")


def save_metrics_to_csv(history, save_path='training_metrics.csv'):
    # ä¿æŒåŸæœ‰å®ç°ä¸å˜
    df = pd.DataFrame(history)
    df.to_csv(save_path, index=False)
    print(f"è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜è‡³: {save_path}")

    print("\nğŸ¯ æœ€ç»ˆè®­ç»ƒç»“æœ:")
    final_metrics = {}
    for key in history:
        if key != 'epoch' and history[key]:
            final_metrics[key] = history[key][-1]

    metric_groups = [
        ['train_loss', 'val_loss'],
        ['train_accuracy', 'val_accuracy'],
        ['train_miou', 'val_miou'],
        ['train_dice', 'val_dice'],
        ['train_f1', 'val_f1'],
        ['train_precision', 'val_precision'],
        ['train_recall', 'val_recall']
    ]

    for group in metric_groups:
        for metric in group:
            if metric in final_metrics and final_metrics[metric] is not None:
                print(f"{metric:.<20} {final_metrics[metric]:.4f}")


def create_dummy_data_loader(batch_size=4, image_size=512, num_samples=32):
    # ä¿æŒåŸæœ‰å®ç°ä¸å˜
    from torch.utils.data import Dataset, DataLoader

    class DummyDataset(Dataset):
        def __len__(self):
            return num_samples

        def __getitem__(self, idx):
            image = torch.randn(3, image_size, image_size)
            mask = torch.bernoulli(torch.full((1, image_size, image_size), 0.1)).float()
            return image, mask

    return DataLoader(DummyDataset(), batch_size=batch_size, shuffle=True)


def create_save_directory(base_dir='run', model_name=None):
    """
    åˆ›å»ºä¿å­˜ç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™åˆ›å»ºæ–°ç›®å½•
    
    Args:
        base_dir: åŸºç¡€ç›®å½•
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
    
    Returns:
        save_dir: åˆ›å»ºçš„ä¿å­˜ç›®å½•è·¯å¾„
    """
    if model_name is None:
        # è‡ªåŠ¨ç”Ÿæˆæ¨¡å‹åç§°ï¼ŒåŒ…å«æ—¶é—´æˆ³
        from datetime import datetime
        model_name = f"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    save_dir = os.path.join(base_dir, model_name)
    
    # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œåˆ›å»ºå¸¦åºå·çš„æ–°ç›®å½•
    counter = 1
    original_save_dir = save_dir
    while os.path.exists(save_dir):
        save_dir = f"{original_save_dir}_{counter}"
        counter += 1
    
    os.makedirs(save_dir, exist_ok=True)
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜ç›®å½•: {save_dir}")
    return save_dir


def main():
    # é…ç½®å‚æ•°
    config = {
        'image_size': 512,
        'batch_size': 8,
        'epochs': 5,
        'learning_rate': 1e-4,
        'optimizer': 'adamw',
        'loss_function': 'bce_dice',
        'scheduler': 'plateau',
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',

        # 'train_image_dir': r'/root/autodl-tmp/dataset/all_need_dataset/images/train',
        # 'train_mask_dir': r'/root/autodl-tmp/dataset/all_need_dataset/mask/train',
        # 'val_image_dir': r'/root/autodl-tmp/dataset/all_need_dataset/images/val',
        # 'val_mask_dir': r'/root/autodl-tmp/dataset/all_need_dataset/mask/val',
        'train_image_dir': r'/root/autodl-tmp/dataset/BFA_splitted/train/images',
        'train_mask_dir': r'/root/autodl-tmp/dataset/BFA_splitted/train/masks',
        'val_image_dir': r'/root/autodl-tmp/dataset/BFA_splitted/val/images',
        'val_mask_dir': r'/root/autodl-tmp/dataset/BFA_splitted/val/masks',
        'use_dummy_data': False
    }

    print("ğŸš€ å¼€å§‹è®­ç»ƒæ»‘å¡åˆ†å‰²UNetæ¨¡å‹")
    print("=" * 50)
    print(f"è®¾å¤‡: {config['device']}")
    print(f"å›¾åƒå°ºå¯¸: {config['image_size']}x{config['image_size']}")
    print(f"æ‰¹å¤§å°: {config['batch_size']}")
    print(f"è®­ç»ƒè½®æ•°: {config['epochs']}")
    print(f"å­¦ä¹ ç‡: {config['learning_rate']}")
    print("=" * 50)

    # åˆå§‹åŒ–wandb (æ–°å¢)
    experiment = wandb.init(
        project='U-Net',
        resume='allow',
        anonymous='must',
        config=config  # ç›´æ¥ä¼ å…¥å®Œæ•´é…ç½®
    )

    # åˆ›å»ºæ¨¡å‹
    # model = UNet(n_channels=3, n_classes=1)
    model = ResidualUNet(n_channels=3, n_classes=1)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")
    experiment.log({"total_parameters": total_params})  # è®°å½•å‚æ•°é‡

    # è·å–æ•°æ®åŠ è½½å™¨
    if config.get('use_dummy_data', False):
        print("ä½¿ç”¨è™šæ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
        train_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
        val_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")
    else:
        try:
            train_loader, val_loader = get_data_loaders(
                train_image_dir=config['train_image_dir'],
                train_mask_dir=config['train_mask_dir'],
                val_image_dir=config['val_image_dir'],
                val_mask_dir=config['val_mask_dir'],
                batch_size=config['batch_size'],
                image_size=config['image_size']
            )
            print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
            if val_loader:
                print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("åˆ‡æ¢åˆ°è™šæ‹Ÿæ•°æ®æ¨¡å¼...")
            train_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])
            val_loader = create_dummy_data_loader(config['batch_size'], config['image_size'])

    # è®¾ç½®æŸå¤±å‡½æ•°
    if config['loss_function'] == 'bce':
        import torch.nn as nn
        criterion = nn.BCEWithLogitsLoss()
    elif config['loss_function'] == 'dice':
        from models.losses import DiceLoss
        criterion = DiceLoss()
    else:
        criterion = BCEDiceLoss(bce_weight=0.5, dice_weight=0.5)

    # è®¾ç½®ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨
    optimizer = get_optimizer(model, config['optimizer'], config['learning_rate'])
    scheduler = get_scheduler(optimizer, config['scheduler'])

    # åˆ›å»ºä¿å­˜ç›®å½•
    model_type = "ResidualUNet_adamw"  # æ ¹æ®å®é™…ä½¿ç”¨çš„æ¨¡å‹ä¿®æ”¹
    save_dir = create_save_directory(base_dir='run', model_name=model_type)
    
    # è®¾ç½®ä¿å­˜è·¯å¾„
    best_model_path = os.path.join(save_dir, 'best_landslide_unet.pth')
    final_model_path = os.path.join(save_dir, 'final_landslide_unet.pth')

    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ (ä¼ å…¥wandbå®éªŒå¯¹è±¡)
    trainer = UNetTrainer(
        model, 
        config['device'], 
        train_loader, 
        val_loader, 
        experiment,
        save_dir=save_dir  # ä¼ é€’ä¿å­˜ç›®å½•ç»™è®­ç»ƒå™¨
    )

    print("\nå¼€å§‹è®­ç»ƒ...")
    history = trainer.train(
        epochs=config['epochs'],
        optimizer=optimizer,
        criterion=criterion,
        scheduler=scheduler,
        save_path=best_model_path
    )

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    torch.save({
        'epoch': config['epochs'],
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
        'history': history,
        'config': config
    }, final_model_path)
    print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³: {final_model_path}")

    # ä¿å­˜è®­ç»ƒå›¾è¡¨å’ŒæŒ‡æ ‡åˆ°ä¿å­˜ç›®å½•
    plot_save_path = os.path.join(save_dir, 'training_history.png')
    csv_save_path = os.path.join(save_dir, 'training_metrics.csv')
    
    plot_training_history(history, save_path=plot_save_path)
    save_metrics_to_csv(history, save_path=csv_save_path)
    
    # è®°å½•åˆ°wandb
    experiment.log({
        "training_history": wandb.Image(plot_save_path),
        "best_model": wandb.File(best_model_path),
        "final_model": wandb.File(final_model_path)
    })
    
    experiment.finish()  # ç»“æŸwandbå®éªŒ

    print("\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {save_dir}")
    print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_path}")
    print(f"ğŸ”š æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    
    return model, history, save_dir


if __name__ == "__main__":
    model, history, save_dir = main()